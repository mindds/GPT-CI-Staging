{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.stats import rankdata, spearmanr, f_oneway, kruskal\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_syndromic_dx(response):\n",
    "    # Define the regex pattern to match the confidence level\n",
    "    pattern = r'\\*\\*syndromic diagnosis:\\*\\* (Normal|MCI|Dementia)'\n",
    "    # Search for the pattern in the response\n",
    "    match = re.search(pattern, response, re.IGNORECASE)\n",
    "    # Extract and return the confidence level if found\n",
    "    if match:\n",
    "        return match.group(1).lower()  # Convert to lowercase for consistency\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_confidence_level(response):\n",
    "    # Use regular expression to find the confidence level\n",
    "    match = re.search(r'\\*\\*confidence level:\\*\\*\\s*(\\d+)', response)\n",
    "    \n",
    "    if match:\n",
    "        confidence_level = int(match.group(1))\n",
    "        return confidence_level\n",
    "    else:\n",
    "        return None  \n",
    "    \n",
    "# Function to load all JSON files and combine them into a single DataFrame\n",
    "def load_patient_data(json_directory):\n",
    "    responses = []\n",
    "    predicted_dx = []\n",
    "    patient_ids = []\n",
    "    conf_level = []\n",
    "    # Iterate over all JSON files in the specified directory\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                data_dict = json.load(file)\n",
    "                for patient_id, result in data_dict.items():\n",
    "                    responses.append(result)\n",
    "                    predicted_dx.append(extract_syndromic_dx(result))\n",
    "                    patient_ids.append(patient_id)\n",
    "                    conf_level.append(extract_confidence_level(result))\n",
    "    # Combine all the loaded data into a single DataFrame\n",
    "    combined_data = pd.DataFrame(\n",
    "        {\"PatientID\": patient_ids,\n",
    "        \"ResponseTXT\": responses,\n",
    "        \"predicted_dx\": predicted_dx,\n",
    "        \"confidence_level\": conf_level}\n",
    "    )\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Load the patient data from the JSON files in the specified directory\n",
    "path = \"../Results - sydronmic dx/GPT4o - Attempt 4\"\n",
    "\n",
    "df_result_attempt4 = load_patient_data(path)\n",
    "df_result_attempt4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows where the predicted diagnosis is not one of the expected values\n",
    "df_result_attempt4[~df_result_attempt4['predicted_dx'].isin(['normal', 'mci', 'dementia'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually correct the predicted diagnoses for specific PatientIDs\n",
    "df_result_attempt4.loc[df_result_attempt4['PatientID']=='XXX', 'predicted_dx'] = 'normal'\n",
    "df_result_attempt4.loc[df_result_attempt4['PatientID']=='YYY', 'predicted_dx'] = 'dementia'\n",
    "df_result_attempt4.loc[df_result_attempt4['PatientID']=='ZZZ', 'predicted_dx'] = 'mci'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx = pd.read_csv('../../EDW Queries/Moura et al data-all-notes/patient_dx.csv')\n",
    "df_result = df_result_attempt4.merge(df_dx, on='PatientID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dx_to_category(value):\n",
    "    if value == 0:\n",
    "        return 'CU'\n",
    "    elif value == 2:\n",
    "        return 'MCI'\n",
    "    elif value == 4:\n",
    "        return 'Dementia'\n",
    "    \n",
    "def standardize_dx(value):\n",
    "    if value == 'normal':\n",
    "        return 'CU'\n",
    "    elif value == 'mci':\n",
    "        return 'MCI'\n",
    "    elif value == 'dementia':\n",
    "        return 'Dementia'\n",
    "\n",
    "df_result['actual_category'] = df_result['syndromic_dx'].apply(convert_dx_to_category)\n",
    "\n",
    "df_result['predicted_category'] = df_result['predicted_dx'].apply(standardize_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = ['CU','MCI','Dementia']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(df_result['actual_category'], df_result['predicted_category'], labels=all_labels)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each row by the sum of the row\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create annotation strings for counts and percentages\n",
    "annot = np.array([[\"{0}\\n({1:.1%})\".format(count, perc) for count, perc in zip(row_counts, row_percents)] \n",
    "                  for row_counts, row_percents in zip(cm, cm_normalized)])\n",
    "\n",
    "# Convert the confusion matrix into a DataFrame for easier plotting\n",
    "cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)\n",
    "# Set font style\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Plot the heatmap with both counts and percentages\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(cm, annot=annot, cmap=\"YlGnBu\", fmt=\"\", annot_kws={\"size\": 32}, xticklabels=all_labels, yticklabels=all_labels)\n",
    "\n",
    "plt.xlabel('Predicted', fontsize=35)  \n",
    "plt.ylabel('Actual', fontsize=35)  \n",
    "plt.xticks(fontsize=32)  \n",
    "plt.yticks(fontsize=32)  \n",
    "colorbar = ax.collections[0].colorbar  # Access the color bar\n",
    "colorbar.ax.tick_params(labelsize=24)  # Set font size for color bar tick labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'CU': 0, 'MCI': 1, 'Dementia': 2}\n",
    "\n",
    "# Use .loc to avoid SettingWithCopyWarning\n",
    "df_result.loc[:, 'actual_mapped'] =df_result['actual_category'].map(label_mapping)\n",
    "df_result.loc[:, 'predicted_mapped'] =df_result['predicted_category'].map(label_mapping)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "mae = (df_result['actual_mapped'] -df_result['predicted_mapped']).abs().mean()\n",
    "\n",
    "# Calculate Quadratic Weighted Kappa\n",
    "qwk = cohen_kappa_score(df_result['actual_mapped'],df_result['predicted_mapped'], weights='quadratic')\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Quadratic Weighted Kappa: {qwk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true and predicted labels\n",
    "y_true = df_result['actual_category']\n",
    "y_pred = df_result['predicted_category']\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    labels=['CU', 'MCI', 'Dementia'],  # ensure consistent order\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Display the per-class metrics\n",
    "print(report_df[['precision', 'recall', 'f1-score', 'support']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjudicator Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[df_result['confidence_level'].isna()]\n",
    "df_result.loc[df_result['PatientID']=='XXX', 'confidence_level'] = 90.0\n",
    "df_result.loc[df_result['PatientID']=='YYY', 'confidence_level'] = 85.0\n",
    "df_result.loc[df_result['PatientID']=='ZZZ', 'confidence_level'] = 70.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_certainty = pd.read_csv('../../../../R03/Prelim_Data_R/Dementia_ReferenceStandardDataset_08292019_subset_mrn.csv')\n",
    "df_id = pd.read_csv('../../../EDW Utilities/folder for JH-patient-features/jh_1000_id.csv')\n",
    "df_certainty = df_certainty[['empi','syndromic_dx_certainty']].drop_duplicates().merge(df_id, left_on='empi',right_on='EMPI', how = 'left').dropna()[['PatientID','syndromic_dx_certainty']]\n",
    "df_result = df_result.merge(df_certainty, on='PatientID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_result['syndromic_dx_certainty'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the actual confidence distribution\n",
    "actual_confidence_distribution = counts / counts.sum()\n",
    "\n",
    "# Calculate the cumulative distribution\n",
    "cumulative_distribution = np.cumsum(actual_confidence_distribution)\n",
    "\n",
    "print(\"Actual Confidence Distribution:\\n\", actual_confidence_distribution)\n",
    "print(\"Cumulative Distribution:\\n\", cumulative_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_result, x='actual_category', y='syndromic_dx_certainty')\n",
    "plt.title(\"Adjudicator Confidence Score by Diagnosis Category\")\n",
    "plt.show()\n",
    "\n",
    "cu_scores = df_result[df_result['actual_category'] == 'CU']['syndromic_dx_certainty']\n",
    "mci_scores = df_result[df_result['actual_category'] == 'MCI']['syndromic_dx_certainty']\n",
    "dementia_scores = df_result[df_result['actual_category'] == 'Dementia']['syndromic_dx_certainty']\n",
    "\n",
    "h_stat, p_kw = kruskal(cu_scores, mci_scores, dementia_scores)\n",
    "print(f\"Kruskal-Wallis: H = {h_stat:.3f}, p = {p_kw:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['confidence_level'] = df_result['confidence_level'].astype(float)\n",
    "gpt_confidence_scores = np.array(df_result['confidence_level'].tolist())\n",
    "\n",
    "# Rank the GPT scores to compute quantiles\n",
    "gpt_ranks = rankdata(gpt_confidence_scores, method='average') / len(gpt_confidence_scores)\n",
    "\n",
    "# Map GPT quantiles to actual confidence levels\n",
    "def map_quantile_to_level(gpt_rank):\n",
    "    if gpt_rank <= cumulative_distribution.iloc[0]:\n",
    "        return 1\n",
    "    elif gpt_rank <= cumulative_distribution.iloc[1]:\n",
    "        return 2\n",
    "    elif gpt_rank <= cumulative_distribution.iloc[2]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# Apply the mapping\n",
    "mapped_confidence_levels = np.array([map_quantile_to_level(rank) for rank in gpt_ranks])\n",
    "\n",
    "for gpt_score, mapped_level in zip(gpt_confidence_scores, mapped_confidence_levels):\n",
    "    print(f\"GPT Score: {gpt_score}, Mapped Confidence Level: {mapped_level}\")\n",
    "df_result.loc[:, 'pred_conf_level_mapped'] = mapped_confidence_levels\n",
    "df_result['pred_conf_level_mapped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['syndromic_dx_certainty_int'] = df_result['syndromic_dx_certainty'].astype(int)\n",
    "df_result['syndromic_dx_certainty_str'] = df_result['syndromic_dx_certainty_int'].astype(str)\n",
    "df_result['syndromic_dx_certainty_str'] = pd.Categorical(df_result['syndromic_dx_certainty_str'], \n",
    "                                                         categories=['1', '2', '3', '4'], \n",
    "                                                         ordered=True)\n",
    "df_result['pred_dx_certainty_int'] = df_result['pred_conf_level_mapped'].astype(int)\n",
    "df_result['pred_dx_certainty_str'] = df_result['pred_dx_certainty_int'].astype(str)\n",
    "df_result['pred_dx_certainty_str'] = pd.Categorical(df_result['pred_dx_certainty_str'], \n",
    "                                                         categories=['1', '2', '3', '4'], \n",
    "                                                         ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_data = pd.crosstab(df_result['syndromic_dx_certainty_str'], df_result['pred_dx_certainty_str'])\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax = sns.heatmap(confusion_matrix_data, annot=True, cmap=\"YlGnBu\", fmt=\"d\", annot_kws={\"size\": 34})\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('GPT Label', fontsize=35)  \n",
    "plt.ylabel('Physician Label', fontsize=35)  \n",
    "plt.xticks(fontsize=32) \n",
    "plt.yticks(fontsize=32) \n",
    "colorbar = ax.collections[0].colorbar  \n",
    "colorbar.ax.tick_params(labelsize=24) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_kappa_by_certainty(df):\n",
    "    kappa_scores = {}\n",
    "    # Loop through each certainty level\n",
    "    for certainty_level in sorted(df['syndromic_dx_certainty_int'].unique()):\n",
    "        df_subset = df[df['syndromic_dx_certainty_int'] == certainty_level]\n",
    "        # Calculate the weighted kappa score for this subset\n",
    "        kappa_score = cohen_kappa_score(\n",
    "            df_subset['actual_mapped'], \n",
    "            df_subset['predicted_mapped'], \n",
    "            weights='quadratic'\n",
    "        )\n",
    "        kappa_scores[certainty_level] = kappa_score\n",
    "\n",
    "    return kappa_scores\n",
    "\n",
    "kappa_scores_by_certainty = calculate_weighted_kappa_by_certainty(df_result)\n",
    "\n",
    "for certainty_level, kappa_score in kappa_scores_by_certainty.items():\n",
    "    print(f\"Certainty Level {certainty_level}: Weighted Kappa = {kappa_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_df_gpt = pd.DataFrame(list(kappa_scores_by_certainty.items()), columns=['Certainty Level', 'Weighted Kappa'])\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x='Certainty Level', y='Weighted Kappa', data=kappa_df_gpt, hue='Certainty Level', palette='YlGnBu', dodge=False)\n",
    "\n",
    "plt.xlabel('GPT Confidence Score', fontsize=32)\n",
    "plt.ylabel('Weighted Kappa Score', fontsize=32)\n",
    "plt.xticks(fontsize=30)  \n",
    "plt.yticks(fontsize=30)  \n",
    "ax.set_ylim(0, 1.10) \n",
    "\n",
    "# Add text labels on each bar\n",
    "for i, row in kappa_df_gpt.iterrows():\n",
    "    ax.text(i, row['Weighted Kappa'] + 0.005, f'{row[\"Weighted Kappa\"]:.2f}', ha='center', va='bottom', fontsize=30)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision - Logprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and process for logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from file\n",
    "with open(\"../Results - sydronmic dx/GPT4o - Attempt 7 - Revision/patient_group_1_logprobs.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare lists\n",
    "ids = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# Extract the data\n",
    "for pid, result in data.items():\n",
    "    ids.append(pid)\n",
    "    print(result)\n",
    "    predictions.append(result[\"prediction\"])\n",
    "    \n",
    "    # Find probability_percent for the predicted token\n",
    "    pred_token = result[\"prediction\"]\n",
    "    matched_prob = next((item[\"probability_percent\"] for item in result[\"logprobs\"] if item[\"token\"] == pred_token), None)\n",
    "    probabilities.append(matched_prob)\n",
    "\n",
    "# Print result\n",
    "print(\"IDs:\", ids)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Probabilities:\", probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logprob_json(json_directory):\n",
    "    ids = []\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            # Extract the data\n",
    "            for pid, result in data.items():\n",
    "                ids.append(pid)\n",
    "                predictions.append(result[\"prediction\"])\n",
    "                \n",
    "                # Find probability_percent for the predicted token\n",
    "                pred_token = result[\"prediction\"]\n",
    "                matched_prob = next((item[\"probability_percent\"] for item in result[\"logprobs\"] if item[\"token\"] == pred_token), None)\n",
    "                probabilities.append(matched_prob)\n",
    "    combined_data = pd.DataFrame(\n",
    "        {\"PatientID\": ids,\n",
    "        \"predicted_dx\": predictions,\n",
    "        \"probability\": probabilities}\n",
    "    )\n",
    "\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logprobs = load_logprob_json(\"../Results - sydronmic dx/GPT4o - Attempt 7 - Revision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df_logprobs['probability'].tolist(), bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Prediction Probabilities')\n",
    "plt.xlabel('Probability (%)')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx = pd.read_csv('../../EDW Queries/Moura et al data-all-notes/patient_dx.csv')\n",
    "df_combined = df_logprobs.merge(df_dx, on='PatientID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_dx_to_category(value):\n",
    "    if value == '1':\n",
    "        return 'CU'\n",
    "    elif value == '2':\n",
    "        return 'MCI'\n",
    "    elif value == '3':\n",
    "        return 'Dementia'\n",
    "    \n",
    "def actual_dx_to_category(value):\n",
    "    if value == 0:\n",
    "        return 'CU'\n",
    "    elif value == 2:\n",
    "        return 'MCI'\n",
    "    elif value == 4:\n",
    "        return 'Dementia'\n",
    "\n",
    "df_combined['actual_category'] = df_combined['syndromic_dx'].apply(actual_dx_to_category)\n",
    "\n",
    "df_combined['predicted_category'] = df_combined['predicted_dx'].apply(pred_dx_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_combined['syndromic_dx_certainty'].value_counts().sort_index()\n",
    "\n",
    "# Calculate the actual confidence distribution\n",
    "actual_confidence_distribution = counts / counts.sum()\n",
    "\n",
    "# Calculate the cumulative distribution\n",
    "cumulative_distribution = np.cumsum(actual_confidence_distribution)\n",
    "\n",
    "print(\"Actual Confidence Distribution:\\n\", actual_confidence_distribution)\n",
    "print(\"Cumulative Distribution:\\n\", cumulative_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_confidence_scores = np.array(df_combined['probability'].tolist())\n",
    "\n",
    "gpt_ranks = rankdata(gpt_confidence_scores, method='average') / len(gpt_confidence_scores)\n",
    "\n",
    "def map_quantile_to_level(gpt_rank):\n",
    "    if gpt_rank <= cumulative_distribution.iloc[0]:\n",
    "        return 1\n",
    "    elif gpt_rank <= cumulative_distribution.iloc[1]:\n",
    "        return 2\n",
    "    elif gpt_rank <= cumulative_distribution.iloc[2]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "mapped_confidence_levels = np.array([map_quantile_to_level(rank) for rank in gpt_ranks])\n",
    "\n",
    "for gpt_score, mapped_level in zip(gpt_confidence_scores, mapped_confidence_levels):\n",
    "    print(f\"GPT Score: {gpt_score}, Mapped Confidence Level: {mapped_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.loc[:, 'pred_conf_level_mapped'] = mapped_confidence_levels\n",
    "color = sns.color_palette(\"YlGnBu\", as_cmap=True)(0.5)  # 0.5 gives the middle color\n",
    "\n",
    "# Plot a histogram without black rims and with the custom color\n",
    "sns.histplot(df_combined['pred_conf_level_mapped'], bins=4, kde=False, color=color, edgecolor='white')\n",
    "plt.title('Distribution of GPT Confidence Scores')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['syndromic_dx_certainty_int'] = df_combined['syndromic_dx_certainty'].astype(int)\n",
    "df_combined['syndromic_dx_certainty_str'] = df_combined['syndromic_dx_certainty_int'].astype(str)\n",
    "df_combined['syndromic_dx_certainty_str'] = pd.Categorical(df_combined['syndromic_dx_certainty_str'], \n",
    "                                                         categories=['1', '2', '3', '4'], \n",
    "                                                         ordered=True)\n",
    "df_combined['pred_dx_certainty_int'] = df_combined['pred_conf_level_mapped'].astype(int)\n",
    "df_combined['pred_dx_certainty_str'] = df_combined['pred_dx_certainty_int'].astype(str)\n",
    "df_combined['pred_dx_certainty_str'] = pd.Categorical(df_combined['pred_dx_certainty_str'], \n",
    "                                                         categories=['1', '2', '3', '4'], \n",
    "                                                         ordered=True)\n",
    "confusion_matrix_data = pd.crosstab(df_combined['syndromic_dx_certainty_str'], df_combined['pred_dx_certainty_str'])\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax = sns.heatmap(confusion_matrix_data, annot=True, cmap=\"YlGnBu\", fmt=\"d\", annot_kws={\"size\": 34})\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('GPT Confidence', fontsize=35)  \n",
    "plt.ylabel('Physician Confidence', fontsize=35) \n",
    "plt.xticks(fontsize=32) \n",
    "plt.yticks(fontsize=32)  \n",
    "colorbar = ax.collections[0].colorbar  \n",
    "colorbar.ax.tick_params(labelsize=24) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scores_by_certainty = calculate_weighted_kappa_by_certainty(df_combined)\n",
    "\n",
    "for certainty_level, kappa_score in kappa_scores_by_certainty.items():\n",
    "    print(f\"Certainty Level {certainty_level}: Weighted Kappa = {kappa_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_df_gpt = pd.DataFrame(list(kappa_scores_by_certainty.items()), columns=['Certainty Level', 'Weighted Kappa'])\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x='Certainty Level', y='Weighted Kappa', data=kappa_df_gpt, palette='YlGnBu', dodge=False)\n",
    "\n",
    "plt.xlabel('GPT Confidence Score', fontsize=32)\n",
    "plt.ylabel('Weighted Kappa Score', fontsize=32)\n",
    "plt.xticks(fontsize=30)  \n",
    "plt.yticks(fontsize=30)  \n",
    "ax.set_ylim(0, 1.10)  \n",
    "\n",
    "for i, row in kappa_df_gpt.iterrows():\n",
    "    ax.text(i, row['Weighted Kappa'] + 0.005, f'{row[\"Weighted Kappa\"]:.2f}', ha='center', va='bottom', fontsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision - 5 Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and process for 5 classes experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_syndromic_dx(response):\n",
    "    # Updated regex pattern to include new categories\n",
    "    pattern = r'\\*\\*syndromic diagnosis:\\*\\*\\s*(Normal vs MCI|MCI vs Dementia|Normal|MCI|Dementia)'\n",
    "    match = re.search(pattern, response, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).lower()  # Normalize to lowercase\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Function to load all JSON files and combine them into a single DataFrame\n",
    "def load_patient_data(json_directory):\n",
    "    responses = []\n",
    "    predicted_dx = []\n",
    "    patient_ids = []\n",
    "    # Iterate over all JSON files in the specified directory\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(json_directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                data_dict = json.load(file)\n",
    "                for patient_id, result in data_dict.items():\n",
    "                    responses.append(result)\n",
    "                    predicted_dx.append(extract_syndromic_dx(result))\n",
    "                    patient_ids.append(patient_id)\n",
    "    # Combine all the loaded data into a single DataFrame\n",
    "    combined_data = pd.DataFrame(\n",
    "        {\"PatientID\": patient_ids,\n",
    "        \"ResponseTXT\": responses,\n",
    "        \"predicted_dx\": predicted_dx}\n",
    "    )\n",
    "\n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = load_patient_data(\".../Results - sydronmic dx/GPT4o - Attempt 8 - Revision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx = pd.read_csv('../../EDW Queries/Moura et al data-all-notes/patient_dx.csv')\n",
    "df_combined = df_result.merge(df_dx, on='PatientID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_dx_to_category(value):\n",
    "    if value == 'normal':\n",
    "        return 'Normal'\n",
    "    elif value == 'normal vs mci':\n",
    "        return 'Normal-to-MCI'\n",
    "    elif value == 'mci':\n",
    "        return 'MCI'\n",
    "    elif value == 'mci vs dementia':\n",
    "        return 'MCI-to-Dementia'\n",
    "    elif value == 'dementia':\n",
    "        return 'Dementia'\n",
    "    \n",
    "def actual_dx_to_category(value):\n",
    "    if value == 0:\n",
    "        return 'Normal'\n",
    "    elif value == 1:\n",
    "        return 'Normal-to-MCI'\n",
    "    elif value == 2:\n",
    "        return 'MCI'\n",
    "    elif value == 3:\n",
    "        return 'MCI-to-Dementia'\n",
    "    elif value == 4:\n",
    "        return 'Dementia'\n",
    "\n",
    "    \n",
    "# Apply the function to the 'cdr' column and create a new 'cdr_category' column\n",
    "df_combined['actual_category'] = df_combined['syndromic_dx'].apply(actual_dx_to_category)\n",
    "\n",
    "df_combined['predicted_category'] = df_combined['predicted_dx'].apply(pred_dx_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['actual_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = ['Normal','Normal-to-MCI','MCI','MCI-to-Dementia','Dementia']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(df_combined['actual_category'], df_combined['predicted_category'], labels=all_labels)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each row by the sum of the row\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation strings for counts and percentages\n",
    "annot = np.array([[\"{0}\\n({1:.1%})\".format(count, perc) for count, perc in zip(row_counts, row_percents)] \n",
    "                  for row_counts, row_percents in zip(cm, cm_normalized)])\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)\n",
    "# Set font style\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "plt.figure(figsize=(16, 13))\n",
    "ax = sns.heatmap(cm, annot=annot, cmap=\"YlGnBu\", fmt=\"\", annot_kws={\"size\": 32}, xticklabels=all_labels, yticklabels=all_labels)\n",
    "\n",
    "plt.xlabel('Predicted', fontsize=35) \n",
    "plt.ylabel('Actual', fontsize=35) \n",
    "plt.xticks(fontsize=24)  \n",
    "plt.yticks(fontsize=24)  \n",
    "colorbar = ax.collections[0].colorbar \n",
    "colorbar.ax.tick_params(labelsize=24)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true and predicted labels\n",
    "y_true = df_combined['actual_category']\n",
    "y_pred = df_combined['predicted_category']\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    labels=['Normal','Normal-to-MCI','MCI','MCI-to-Dementia','Dementia'],  # ensure consistent order\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Display the per-class metrics\n",
    "print(report_df[['precision', 'recall', 'f1-score', 'support']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'Normal': 0, 'MCI': 2, 'Dementia': 4, 'Normal-to-MCI': 1, 'MCI-to-Dementia': 3}\n",
    "\n",
    "# Use .loc to avoid SettingWithCopyWarning\n",
    "df_combined.loc[:, 'actual_mapped'] = df_combined['actual_category'].map(label_mapping)\n",
    "df_combined.loc[:, 'predicted_mapped'] = df_combined['predicted_category'].map(label_mapping)\n",
    "\n",
    "# Calculate Quadratic Weighted Kappa\n",
    "qwk = cohen_kappa_score(df_combined['actual_mapped'], df_combined['predicted_mapped'], weights='quadratic')\n",
    "\n",
    "print(f\"Quadratic Weighted Kappa: {qwk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjudicator Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.merge(df_certainty, on='PatientID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = df_combined[df_combined['actual_category'] == 'Normal']\n",
    "print(normal_df.syndromic_dx_certainty.mean())\n",
    "normalmci_df = df_combined[df_combined['actual_category'] == 'Normal-to-MCI']\n",
    "print(normalmci_df.syndromic_dx_certainty.mean())\n",
    "mci_df = df_combined[df_combined['actual_category'] == 'MCI']\n",
    "print(mci_df.syndromic_dx_certainty.mean())\n",
    "mcidementia_df = df_combined[df_combined['actual_category'] == 'MCI-to-Dementia']\n",
    "print(mcidementia_df.syndromic_dx_certainty.mean())\n",
    "dem_df = df_combined[df_combined['actual_category'] == 'Dementia']\n",
    "print(dem_df.syndromic_dx_certainty.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty_ls = [\n",
    "    3.215909090909091,\n",
    "    1.565217391304348,\n",
    "    2.596774193548387,\n",
    "    2.090909090909091,\n",
    "    3.6339285714285716\n",
    "]\n",
    "levels = ['CU', 'Normal vs. MCI', 'MCI', 'MCI vs. Dementia', 'Dementia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty_df = pd.DataFrame({\n",
    "    'CI Stage': levels,\n",
    "    'Mean Certainty Level': certainty_ls\n",
    "})\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.barplot(x='CI Stage', y='Mean Certainty Level', data=certainty_df, hue='Mean Certainty Level', palette='YlGnBu', dodge=False)\n",
    "ax.legend_.remove()\n",
    "plt.xlabel('Syndromic Dx', fontsize=32)\n",
    "plt.ylabel('Mean Confidence Level', fontsize=32)\n",
    "plt.xticks(fontsize=30, rotation=30)\n",
    "plt.yticks(fontsize=30)\n",
    "ax.set_ylim(0, 4.0)  \n",
    "\n",
    "# Add text labels on each bar\n",
    "for i, row in certainty_df.iterrows():\n",
    "    ax.text(i, row['Mean Certainty Level'] + 0.05, f'{row[\"Mean Certainty Level\"]:.2f}', \n",
    "            ha='center', va='bottom', fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
