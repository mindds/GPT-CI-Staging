{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import os\n",
    "# disable tokenizers parallelism to avoid warnings or deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(default_credential, \"https://cognitiveservices.azure.com/.default\" )\n",
    "\n",
    "api_type = \"azure\"\n",
    "api_base = \"https://mgh-mind-data-science-private-e2-openai-service.openai.azure.com/\" \n",
    "api_version = \"2024-05-13-preview\"\n",
    "\n",
    "client = openai.AzureOpenAI(api_version=api_version, azure_endpoint=api_base, azure_ad_token_provider=token_provider )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging with progress notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_path = \"../cdr_preprocessed_strict_0827.csv\"\n",
    "note_df = pd.read_csv(note_path, index_col=False)\n",
    "note_df = note_df.drop(columns=\"Unnamed: 0\")\n",
    "note_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = list(note_df['CleanedNoteTXT'])\n",
    "print(notes[0])\n",
    "print(\"The global CDR is \",note_df['GlobalCDR'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_note(prompt, note_text):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"GPT-4o-model\", # model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{note_text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities. \n",
    "Based on your assessment, classify the severity of the dementia using the Clinical Dementia Rating (CDR) scale, where:\n",
    "- 0 = No dementia\n",
    "- 0.5 = Questionable dementia (Very mild impairment)\n",
    "- 1 = Mild dementia\n",
    "- 2 = Moderate dementia\n",
    "- 3 = Severe dementia\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the CDR score (0, 0.5, 1, 2, or 3) and a brief justification.\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3 - Return Scores and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the CDR score (0, 0.5, 1, 2, or 3) and a brief justification.\n",
    "Your response should have this format at the end for final conclusion of CDR score:\n",
    "\n",
    "**CDR Score:**\n",
    "[Insert CDR score here]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cdr_score(response):\n",
    "    # Use regex to find the CDR score in the response\n",
    "    match = re.search(r\"\\*\\*CDR Score:\\*\\*\\s*(\\d(\\.\\d)?)\", response)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "cdr_score = extract_cdr_score(response)\n",
    "print(\"The predicted global CDR is \",cdr_score)\n",
    "print(\"The actual global CDR is \",note_df['GlobalCDR'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 4 - Add guidance on output format (domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the CDR score (0, 0.5, 1, 2, or 3) and a brief justification.\n",
    "Your response should follow this format:\\n\\n\n",
    "**Summary and Assessment:**\\n[Your summary here]\\n\\n\n",
    "**Domain-Specific Observations:**\\n\n",
    "1. Memory: [Your observation here]\\n\n",
    "2. Orientation: [Your observation here]\\n\n",
    "3. Judgment and Problem Solving: [Your observation here]\\n\n",
    "4. Community Affairs: [Your observation here]\\n\n",
    "5. Home and Hobbies: [Your observation here]\\n\n",
    "6. Personal Care: [Your observation here]\\n\\n\n",
    "**CDR Score:**\\n[Insert CDR score here, e.g., 2.0]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the CDR score (0, 0.5, 1, 2, or 3) and a brief justification. Do not include patient name or any identifiable info in response.\n",
    "Follow this format:\\n\\n\n",
    "**Summary and Assessment:**\\n[Your summary here]\\n\\n\n",
    "**Domain-Specific Observations:**\\n\n",
    "1. Memory: [Very brief observation here]\\n\n",
    "2. Orientation: [Very brief observation here]\\n\n",
    "3. Judgment and Problem Solving: [Very brief observation here]\\n\n",
    "4. Community Affairs: [Very brief observation here]\\n\n",
    "5. Home and Hobbies: [Very brief observation here]\\n\n",
    "6. Personal Care: [Very brief observation here]\\n\\n\n",
    "**CDR Score:**\\n[Insert CDR score here, e.g., 2.0]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the global CDR score (0, 0.5, 1, 2, or 3) and a brief justification. \n",
    "Follow this format and do not include patient name in response.:\\n\\n\n",
    "**Domain-Specific Observations:**\\n\n",
    "1. Memory: [Very brief observation here]\\n\n",
    "2. Orientation: [Very brief observation here]\\n\n",
    "3. Judgment and Problem Solving: [Very brief observation here]\\n\n",
    "4. Community Affairs: [Very brief observation here]\\n\n",
    "5. Home and Hobbies: [Very brief observation here]\\n\n",
    "6. Personal Care: [Very brief observation here]\\n\\n\n",
    "**CDR Score:**\\n[Insert barely CDR score here, e.g., 2.0]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_score = extract_cdr_score(response.choices[0].message.content)\n",
    "print(\"The predicted global CDR is \",cdr_score)\n",
    "print(\"The actual global CDR is \",note_df['GlobalCDR'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 5 - Concise Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score. Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care) and give a brief justification for the score. Keep the response concise. Do not include patient name or any identifiable info in response.\n",
    "Response format:\n",
    "**CDR Score:** [Insert CDR score here]\n",
    "**Justification:** [A few sentences summarizing key observations]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score. Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care).\n",
    "Keep the response concise and follow this format:\\n\\n\n",
    "**CDR Score:** [Insert barely CDR score here, e.g., 2.0. Only assigne if the evidence strongly supports it!]\n",
    "**Justification:** [A few sentences summarizing key observations. do not include patient name.]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through progress notes\n",
    "results = []\n",
    "for i, note in enumerate(notes[:10]):\n",
    "    start_time = time.time() \n",
    "    response = simple_note(prompt, note)\n",
    "    cdr_score = extract_cdr_score(response)\n",
    "    results.append({\n",
    "        \"CDR Score\": cdr_score,\n",
    "        \"Full Response\": response\n",
    "    })\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = end_time - start_time \n",
    "    print(f\"Time taken for case {i+1}: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 6 - Multiple Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stage_dementia(progress_notes):\n",
    "    domains = [\"Memory\", \"Orientation\", \"Judgment and Problem Solving\",\n",
    "               \"Community Affairs\", \"Home and Hobbies\", \"Personal Care\"]\n",
    "    cdr_scores = {}\n",
    "    domain_summaries = []\n",
    "    for domain in domains:\n",
    "        prompt = f\"Analyze the following progress note for information related to {domain}. \" \\\n",
    "                 f\"Provide classification of the CDR score (0, 0.5, 1, 2, or 3) for the {domain} impairment (be very concise and no need for justification).\\n\\n\" \\\n",
    "        \n",
    "        domain_response = simple_note(prompt, progress_notes)\n",
    "        \n",
    "        # Store the response for this domain\n",
    "        cdr_scores[domain] = domain_response\n",
    "        \n",
    "        # Summarize the response for use in the overall CDR prompt\n",
    "        domain_summaries.append(f\"{domain}: {domain_response}\")\n",
    "    \n",
    "    # Combine domain summaries into a single text block\n",
    "    combined_summary = \"\\n\".join(domain_summaries)\n",
    "    \n",
    "    # Use the combined summary to inform the overall CDR score\n",
    "    combination_prompt = \"Based on the following classifications for each domain, determine the overall CDR score.\\n\\n\" \\\n",
    "                         f\"{combined_summary}\\n\\n\" \\\n",
    "                         \"Provide the overall CDR score as a single number (e.g., 'CDR Score: 1.0').\"\n",
    "    overall_cdr = simple_note(combination_prompt, progress_notes)\n",
    "    \n",
    "    return overall_cdr, cdr_scores\n",
    "\n",
    "cdr_score = stage_dementia(notes[0])\n",
    "print(f\"global CDR Score: {cdr_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 7 - Less Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score. Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care).\n",
    "Keep the response concise and follow this format:\\n\\n\n",
    "**CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "**Justification:** [A few sentences summarizing key observations. do not include patient name.]\"\"\"\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through progress notes\n",
    "results = []\n",
    "for i, note in enumerate(notes[:10]):\n",
    "    start_time = time.time() \n",
    "    response = simple_note(prompt, note)\n",
    "    cdr_score = extract_cdr_score(response)\n",
    "    results.append({\n",
    "        \"CDR Score\": cdr_score,\n",
    "        \"Full Response\": response\n",
    "    })\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = end_time - start_time \n",
    "    print(f\"Time taken for case {i+1}: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 8 - Confidence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score. \n",
    "Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care). Then, provide a confidence level (low, medium, or high) based on the clarity and consistency of the evidence from these six aspects. If evidence is mixed or not strong, choose \"medium\" or \"low.\" \n",
    "Keep the response concise and follow this format:\\n\\n\n",
    "**CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "**Justification:** [A few sentences summarizing key observations. do not include patient name.]\n",
    "**Confidence Level:** [Insert your confidence level in this decision as \"low,\" \"medium,\" or \"high\"]\"\"\"\n",
    "\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score.  Do not include patient name in response for information protection.\n",
    "Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care). Then, provide a confidence level (low, medium, or high) based on the clarity and consistency of the evidence from these six aspects. Use \"high\" confidence only if the evidence is strong and leaves little doubt about the staging. Otherwise, choose \"medium\" or \"low.\" \n",
    "Keep the response concise and follow this format:\\n\\n\n",
    "**CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "**Justification:** [A few sentences summarizing key observations. ]\n",
    "**Confidence Level:** [Insert your confidence level in this decision as \"low,\" \"medium,\" or \"high\"]\"\"\"\n",
    "\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_confidence_level(response):\n",
    "    # Define the regex pattern to match the confidence level\n",
    "    pattern = r'\\*\\*Confidence Level:\\*\\* (low|medium|high)'\n",
    "    # Search for the pattern in the response\n",
    "    match = re.search(pattern, response, re.IGNORECASE)\n",
    "    # Extract and return the confidence level if found\n",
    "    if match:\n",
    "        return match.group(1).lower()  # Convert to lowercase for consistency\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through progress notes\n",
    "results = []\n",
    "for i, note in enumerate(notes[:10]):\n",
    "    start_time = time.time() \n",
    "    response = simple_note(prompt, note)\n",
    "    cdr_score = extract_cdr_score(response)\n",
    "    conf_level = extract_confidence_level(response)\n",
    "    results.append({\n",
    "        \"CDR Score\": cdr_score,\n",
    "        \"Confidence Level\": conf_level, \n",
    "        \"Full Response\": response\n",
    "    })\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = end_time - start_time \n",
    "    print(f\"Time taken for case {i+1}: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    print(f\"The confidence level of prediction is: {result['Confidence Level']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 9 - Count Domains and Confidence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score.  Do not include patient name in response for information protection.\n",
    "    Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care) and identify whether there are clear clues that can help determine the dementia stage. Then, summarize how many domains have explicit information mentioned.\n",
    "    Provide a confidence level (low, medium, or high) based on the clarity and consistency of the evidence from these six domains. Use \"high\" confidence only if the evidence is explicitly mentioned in most domains and consistent across domains. \n",
    "    Keep the response concise and follow this format:\\n\\n\n",
    "    **CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "    **Justification:** [A few sentences summarizing key observations. ]\n",
    "    **# of Domains Explicitly Mentioned:** [Insert number of domains that are clearly observed, e.g., 2]\n",
    "    **Confidence Level:** [Insert your confidence level in this decision as \"low,\" \"medium,\" or \"high\"]\"\"\"\n",
    "\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_domain(response):\n",
    "    # Use regex to find the CDR score in the response\n",
    "    pattern = r'\\*\\*# of Domains Explicitly Mentioned:\\*\\* (\\d+)'\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Convert to an integer\n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through progress notes\n",
    "results = []\n",
    "for i, note in enumerate(notes[:10]):\n",
    "    start_time = time.time() \n",
    "    response = simple_note(prompt, note)\n",
    "    cdr_score = extract_cdr_score(response)\n",
    "    num_domain = extract_num_domain(response)\n",
    "    conf_level = extract_confidence_level(response)\n",
    "    results.append({\n",
    "        \"CDR Score\": cdr_score,\n",
    "        \"Num of Domains\": num_domain,\n",
    "        \"Confidence Level\": conf_level, \n",
    "        \"Full Response\": response\n",
    "    })\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = end_time - start_time \n",
    "    print(f\"Time taken for case {i+1}: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    print(f\"Number of explicitly mentioned domains: {result['Num of Domains']}\")\n",
    "    print(f\"The confidence level of prediction is: {result['Confidence Level']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 10 - Make it conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score.  Do not include patient name in response for information protection.\n",
    "Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care) and identify whether there are clear clues that can help determine the dementia stage. Then, summarize how many domains have explicit information mentioned.\n",
    "Provide a confidence level (low, medium, or high) based on the clarity and consistency of the evidence from these six domains. Start with an assumption of \"low\" confidence in your decision. Increase the confidence to \"medium\" only if there is strong, consistent evidence across multiple domains. Use \"high\" only if the evidence is really clear and leaves little room for doubt.\n",
    "Keep the response concise and follow this format:\\n\\n\n",
    "**CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "**Justification:** [A few sentences summarizing key observations. ]\n",
    "**# of Domains Explicitly Mentioned:** [Insert number of domains that are clearly observed, e.g., 2]\n",
    "**Confidence Level:** [Insert your confidence level in this decision as \"low,\" \"medium,\" or \"high\"]\"\"\"\n",
    "\n",
    "response = simple_note(prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through progress notes\n",
    "results = []\n",
    "for i, note in enumerate(notes[:10]):\n",
    "    start_time = time.time() \n",
    "    response = simple_note(prompt, note)\n",
    "    cdr_score = extract_cdr_score(response)\n",
    "    num_domain = extract_num_domain(response)\n",
    "    conf_level = extract_confidence_level(response)\n",
    "    results.append({\n",
    "        \"CDR Score\": cdr_score,\n",
    "        \"Num of Domains\": num_domain,\n",
    "        \"Confidence Level\": conf_level, \n",
    "        \"Full Response\": response\n",
    "    })\n",
    "\n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = end_time - start_time \n",
    "    print(f\"Time taken for case {i+1}: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"The actual global CDR: {note_df['GlobalCDR'][i]}\")\n",
    "    print(f\"The predicted global CDR: {result['CDR Score']}\")\n",
    "    print(f\"Number of explicitly mentioned domains: {result['Num of Domains']}\")\n",
    "    print(f\"The confidence level of prediction is: {result['Confidence Level']}\")\n",
    "    # print(\"Full Response:\\n\", result['Full Response'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 11 - Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_prompt = f\"\"\"Based on the following progress notes, classify the patient's global Clinical Dementia Rating (CDR) score into one of the following:\n",
    "0, 0.5, 1.0, 2.0, or 3.0. Only output the score as a number (e.g., 1.0) with no explanation or formatting.\n",
    "\"\"\"\n",
    "response = simple_note(score_prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdr_scoring(prompt, note_text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-model2\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a neurologist tasked with cognitive impairment assessment, including Clinical Dementia Rating (CDR) scoring\"},\n",
    "            {\"role\": \"user\", \n",
    "            \"content\": f\"\"\"Here is the progress note of the patient: {note_text}\n",
    "            {prompt}\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        temperature = 0,\n",
    "        logprobs=True,\n",
    "        top_logprobs=3\n",
    "    )\n",
    "    # Extract top logprobs\n",
    "    top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "    \n",
    "    # Format logprobs\n",
    "    formatted_logprobs = [\n",
    "        {\n",
    "            \"token\": logprob.token,\n",
    "            \"logprob\": logprob.logprob,\n",
    "            \"probability_percent\": np.round(np.exp(logprob.logprob)*100, 2)\n",
    "        }\n",
    "        for logprob in top_logprobs\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": response.choices[0].message.content,\n",
    "        \"logprobs\": formatted_logprobs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cdr_scoring(score_prompt, notes[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the patient's ability in Orientation domain?\"\n",
    "probe_prompt = f\"\"\"You retrieved the progress note of a patient: {notes[0]}. The question is: {question}.\n",
    "Before even answering the question, consider whether you have sufficient information in the note to answer the question fully.\n",
    "Your output should JUST be the boolean true or false, of if you have sufficient information in the note to answer the question.\n",
    "Respond with just one word, 'True', or the word 'False', nothing else.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_sufficiency(prompt, note_text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-model2\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a neurologist tasked with cognitive impairment assessment, including Clinical Dementia Rating (CDR) scoring\"},\n",
    "            {\"role\": \"user\", \n",
    "            \"content\": f\"\"\"Here is the progress note of the patient: {note_text}\n",
    "            {prompt}\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        temperature = 0,\n",
    "        logprobs=True,\n",
    "        top_logprobs=2\n",
    "    )\n",
    "    # Extract top logprobs\n",
    "    top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "    \n",
    "    # Format logprobs\n",
    "    formatted_logprobs = [\n",
    "        {\n",
    "            \"token\": logprob.token,\n",
    "            \"logprob\": logprob.logprob,\n",
    "            \"probability_percent\": np.round(np.exp(logprob.logprob)*100, 2)\n",
    "        }\n",
    "        for logprob in top_logprobs\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": response.choices[0].message.content,\n",
    "        \"logprobs\": formatted_logprobs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_sufficiency(probe_prompt, notes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_domain_sufficiency(note_text):\n",
    "    domain_sufficiency = {}\n",
    "    cdr_domain_questions = {\n",
    "        \"Memory\": \"What is the patient's ability in CDR Memory domain?\",\n",
    "        \"Orientation\": \"What is the patient's ability in CDR Orientation domain?\",\n",
    "        \"Judgment and Problem Solving\": \"What is the patient's ability in CDR Judgment and Problem Solving domain?\",\n",
    "        \"Community Affairs\": \"What is the patient's ability in CDR Community Affairs domain?\",\n",
    "        \"Home and Hobbies\": \"What is the patient's ability in CDR Home and Hobbies domain?\",\n",
    "        \"Personal Care\": \"What is the patient's ability in CDR Personal Care domain?\"\n",
    "    }\n",
    "    for domain, question in cdr_domain_questions.items():\n",
    "        prompt = f\"\"\"You retrieved the progress note of a patient: {note_text}. The question is: {question}.\n",
    "        Before even answering the question, consider whether you have sufficient information in the note to answer the question fully in **formal CDR definitions**.\n",
    "        Note that you're looking for {domain} domain-specific behaviors or observations.\n",
    "        Your output should JUST be one word, the boolean 'True' or 'False', of if you have very sufficient information in the note to answer the question.\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-model2\",\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a neurologist tasked with cognitive impairment assessment, including Clinical Dementia Rating (CDR) scoring\"},\n",
    "                {\"role\": \"user\", \n",
    "                \"content\": prompt}\n",
    "            ],\n",
    "            temperature = 0,\n",
    "            logprobs=True,\n",
    "            top_logprobs=2\n",
    "        )\n",
    "        top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "    \n",
    "        # Format logprobs\n",
    "        formatted_logprobs = [\n",
    "            {\n",
    "                \"token\": logprob.token,\n",
    "                \"logprob\": logprob.logprob,\n",
    "                \"probability_percent\": np.round(np.exp(logprob.logprob)*100, 2)\n",
    "            }\n",
    "            for logprob in top_logprobs\n",
    "        ]\n",
    "        domain_sufficiency[domain] = {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"logprobs\": formatted_logprobs\n",
    "        }\n",
    "\n",
    "    return domain_sufficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_domain_sufficiency(notes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_note_with_timing(prompt, note_text, id):\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"GPT-4o-model\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{note_text}\"}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            return response.choices[0].message.content, duration, id\n",
    "        except:\n",
    "            print(\"Rate limit exceeded. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_groups(progress_notes_list, num_groups):\n",
    "    # Divide the list into 'num_groups' parts\n",
    "    avg_len = len(progress_notes_list) // num_groups\n",
    "    groups = [progress_notes_list[i * avg_len:(i + 1) * avg_len] for i in range(num_groups - 1)]\n",
    "    groups.append(progress_notes_list[(num_groups - 1) * avg_len:])  # Append the remaining items\n",
    "    return groups, avg_len\n",
    "\n",
    "# progress_notes_list = note_df\n",
    "groups, size_of_each_group = divide_into_groups(notes, 43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_dementia_parallel(note_text, prompt, max_workers=16):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for index, note in enumerate(note_text):\n",
    "            futures.append(executor.submit(simple_note_with_timing, prompt, note, index))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            response, duration, index = future.result()\n",
    "            cdr = extract_cdr_score(response)\n",
    "            results.append({\"case_id\": index, \"response\": response, \"CDR\": cdr, \"duration\": duration})\n",
    "    # Sort results by case_id to maintain the original order\n",
    "    results.sort(key=lambda x: x['case_id'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_group_index = 0\n",
    "path = \"../Results/GPT4o Attempt 4\"\n",
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the global CDR score (0, 0.5, 1, 2, or 3) and a brief justification. \n",
    "        Follow this format and do not include patient name in response.:\\n\\n\n",
    "        **Domain-Specific Observations:**\\n\n",
    "        1. Memory: [Very brief observation here]\\n\n",
    "        2. Orientation: [Very brief observation here]\\n\n",
    "        3. Judgment and Problem Solving: [Very brief observation here]\\n\n",
    "        4. Community Affairs: [Very brief observation here]\\n\n",
    "        5. Home and Hobbies: [Very brief observation here]\\n\n",
    "        6. Personal Care: [Very brief observation here]\\n\\n\n",
    "        **CDR Score:**\\n[Insert barely CDR score here, e.g., 2.0]\"\"\"\n",
    "\n",
    "for group_index, group in enumerate(groups[start_group_index:]):\n",
    "    print(f\"Processing group {group_index + start_group_index + 1} of {len(groups)}...\")\n",
    "    save_results = stage_dementia_parallel(group, prompt, max_workers=16)\n",
    "\n",
    "    # Step 3: Save the results to a JSON file with the path\n",
    "    filename = f\"group_{group_index + start_group_index + 1}_results.json\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(save_results, json_file, indent=4)\n",
    "    print(f\"Results saved to {file_path}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_group_index = 0\n",
    "path = \"../Results/GPT4o Attempt 9\"\n",
    "prompt = \"\"\"Review the following progress notes and provide a global CDR score.  Do not include patient name in response for information protection.\n",
    "    Focus on key observations for each domain (Memory, Orientation, Judgment and Problem Solving, Community Affairs, Home and Hobbies, Personal Care) and identify whether there are clear clues that can help determine the dementia stage. Then, summarize how many domains have explicit information mentioned.\n",
    "    Provide a confidence level (low, medium, or high) based on the clarity and consistency of the evidence from these six domains. Use \"high\" confidence only if the evidence is explicitly mentioned in most domains and consistent across domains. \n",
    "    Keep the response concise and follow this format:\\n\\n\n",
    "    **CDR Score:** [Insert barely CDR score here, e.g., 2.0. Do not assign a high score unless the evidence strongly supports it!]\n",
    "    **Justification:** [A few sentences summarizing key observations. ]\n",
    "    **# of Domains Explicitly Mentioned:** [Insert number of domains that are clearly observed, e.g., 2]\n",
    "    **Confidence Level:** [Insert your confidence level in this decision as \"low,\" \"medium,\" or \"high\"]\"\"\"\n",
    "\n",
    "\n",
    "for group_index, group in enumerate(groups[start_group_index:]):\n",
    "    print(f\"Processing group {group_index + start_group_index + 1} of {len(groups)}...\")\n",
    "    save_results = stage_dementia_parallel(group, prompt, max_workers=16)\n",
    "\n",
    "    # Step 3: Save the results to a JSON file with the path\n",
    "    filename = f\"group_{group_index + start_group_index + 1}_results.json\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(save_results, json_file, indent=4)\n",
    "    print(f\"Results saved to {file_path}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdr_scoring(prompt, note_text, id):\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-model2\",\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a neurologist tasked with cognitive impairment assessment, including Clinical Dementia Rating (CDR) scoring\"},\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": f\"\"\"Here is the progress note of the patient: {note_text}\n",
    "                    {prompt}\n",
    "                    \"\"\"}\n",
    "                ],\n",
    "                temperature = 0,\n",
    "                logprobs=True,\n",
    "                top_logprobs=3,\n",
    "                max_tokens = 3\n",
    "            )\n",
    "            # Extract top logprobs\n",
    "            top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "            \n",
    "            # Format logprobs\n",
    "            formatted_logprobs = [\n",
    "                {\n",
    "                    \"token\": logprob.token,\n",
    "                    \"logprob\": logprob.logprob,\n",
    "                    \"probability_percent\": np.round(np.exp(logprob.logprob)*100, 2)\n",
    "                }\n",
    "                for logprob in top_logprobs\n",
    "            ]\n",
    "            \n",
    "            return {\"case_id\": id,\n",
    "                \"CDR\": response.choices[0].message.content,\n",
    "                \"logprobs\": formatted_logprobs}\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Rate limit exceeded. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_group_index = 0\n",
    "path = \"../Results/GPT4o Attempt 11\"\n",
    "prompt = f\"\"\"Based on the following progress notes, classify the patient's global Clinical Dementia Rating (CDR) score into one of the following:\n",
    "            0, 0.5, 1.0, 2.0, or 3.0. Only output the score as a number (e.g., 1.0) with no explanation or formatting.\n",
    "            \"\"\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "for group_index, group in enumerate(groups[start_group_index:]):\n",
    "    print(f\"Processing group {group_index + start_group_index + 1} of {len(groups)}...\")\n",
    "    save_results = stage_dementia_parallel(group, prompt, max_workers=16)\n",
    "\n",
    "    # Step 3: Save the results to a JSON file with the path\n",
    "    filename = f\"group_{group_index + start_group_index + 1}_logprobs.json\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(save_results, json_file, indent=4)\n",
    "    print(f\"Results saved to {file_path}\")\n",
    "    # time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_domain_sufficiency(note_text, id):\n",
    "    while True:\n",
    "        try:\n",
    "            domain_sufficiency = {}\n",
    "            cdr_domain_questions = {\n",
    "                \"Memory\": \"What is the patient's ability in CDR Memory domain?\",\n",
    "                \"Orientation\": \"What is the patient's ability in CDR Orientation domain?\",\n",
    "                \"Judgment and Problem Solving\": \"What is the patient's ability in CDR Judgment and Problem Solving domain?\",\n",
    "                \"Community Affairs\": \"What is the patient's ability in CDR Community Affairs domain?\",\n",
    "                \"Home and Hobbies\": \"What is the patient's ability in CDR Home and Hobbies domain?\",\n",
    "                \"Personal Care\": \"What is the patient's ability in CDR Personal Care domain?\"\n",
    "            }\n",
    "            for domain, question in cdr_domain_questions.items():\n",
    "                prompt = f\"\"\"You retrieved the progress note of a patient: {note_text}. The question is: {question}.\n",
    "                Before even answering the question, consider whether you have sufficient information in the note to answer the question fully in **formal CDR definitions**.\n",
    "                Note that you're looking for {domain} domain-specific behaviors or observations.\n",
    "                Your output should JUST be one word, the boolean 'True' or 'False', of if you have very sufficient information in the note to answer the question.\n",
    "                \"\"\"\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-model2\",\n",
    "                    messages = [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a neurologist tasked with cognitive impairment assessment, including Clinical Dementia Rating (CDR) scoring\"},\n",
    "                        {\"role\": \"user\", \n",
    "                        \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature = 0,\n",
    "                    logprobs=True,\n",
    "                    top_logprobs=2\n",
    "                )\n",
    "                top_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "            \n",
    "                # Format logprobs\n",
    "                formatted_logprobs = [\n",
    "                    {\n",
    "                        \"token\": logprob.token,\n",
    "                        \"logprob\": logprob.logprob,\n",
    "                        \"probability_percent\": np.round(np.exp(logprob.logprob)*100, 2)\n",
    "                    }\n",
    "                    for logprob in top_logprobs\n",
    "                ]\n",
    "                domain_sufficiency[domain] = {\n",
    "                    \"answer\": response.choices[0].message.content,\n",
    "                    \"logprobs\": formatted_logprobs\n",
    "                }\n",
    "\n",
    "            return {\"case_id\": id, \"domain_sufficiency\": domain_sufficiency}\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Rate limit exceeded. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sufficiency_parallel(note_text, max_workers=16):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for index, note in enumerate(note_text):\n",
    "            futures.append(executor.submit(check_domain_sufficiency, note, index))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            response = future.result()\n",
    "            results.append(response)\n",
    "    # Sort results by case_id to maintain the original order\n",
    "    results.sort(key=lambda x: x['case_id'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_group_index = 0\n",
    "path = \"../Results/GPT4o Attempt 11 - Sufficiency\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "for group_index, group in enumerate(groups[start_group_index:]):\n",
    "    group_number = group_index + start_group_index + 1\n",
    "    filename = f\"group_{group_number}_sufficiency.json\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File {filename} already exists. Skipping group {group_number}...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Processing group {group_number} of {len(groups)}...\")\n",
    "        save_results = check_sufficiency_parallel(group, max_workers=16)\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(save_results, json_file, indent=4)\n",
    "        print(f\"Results saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG model with knowledge base docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Sources/uds3-ivp-b4.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "    paragraphs = [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]\n",
    "    \n",
    "print(paragraphs)\n",
    "print(len(paragraphs))\n",
    "\n",
    "with open('../Sources/uds3-ivp-b7.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    paragraphs2 = content.split('\\n\\n')\n",
    "    paragraphs2 = [paragraph.strip() for paragraph in paragraphs2 if paragraph.strip()]\n",
    "print(paragraphs2)\n",
    "print(len(paragraphs2))\n",
    "\n",
    "with open('../Sources/ADL vs. iADL.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    paragraphs3 = content.split('\\n\\n')\n",
    "    paragraphs3 = [paragraph.strip() for paragraph in paragraphs3 if paragraph.strip()]\n",
    "print(paragraphs3)\n",
    "print(len(paragraphs3))\n",
    "\n",
    "with open('../Sources/ADL.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    paragraphs4 = content.split('\\n\\n')\n",
    "    paragraphs4 = [paragraph.strip() for paragraph in paragraphs4 if paragraph.strip()]\n",
    "print(paragraphs4)\n",
    "print(len(paragraphs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = paragraphs\n",
    "documents.extend(paragraphs2)\n",
    "documents.extend(paragraphs3)\n",
    "documents.extend(paragraphs4)\n",
    "\n",
    "# Load the tokenizer for your model (e.g., GPT-4, GPT-3.5-turbo, or any other causal language model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # Replace with your desired model\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(documents[12])\n",
    "\n",
    "# Calculate the number of tokens\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n",
    "print(f\"Tokens: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define retriever model\n",
    "retriever_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# encoding documents for retrieval\n",
    "doc_embeddings = retriever_model.encode(documents, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG on single note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most similar docs by comparing embeddings\n",
    "def retrieve_documents(query, top_k=3): # note text is used as query in this case\n",
    "    query_embedding = retriever_model.encode(query, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedding, doc_embeddings)\n",
    "    top_results = torch.topk(cosine_scores, k=top_k)\n",
    "    print(top_results[1][0])\n",
    "    return [documents[idx] for idx in top_results[1][0]]\n",
    "\n",
    "def augmented_note(prompt, note_text):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(note_text)\n",
    "    additional_context = \" \".join(retrieved_docs)\n",
    "    \n",
    "    # Combine prompt, note_text, and retrieved documents\n",
    "    combined_prompt = f\"{prompt} Here is some additional information: {additional_context}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-model2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": combined_prompt},\n",
    "            {\"role\": \"user\", \"content\": note_text}\n",
    "        ],\n",
    "        temperature = 0,\n",
    "        max_tokens = 4096\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the global CDR score (0, 0.5, 1, 2, or 3) and a brief justification. \n",
    "        Follow this format and do not include patient name in response.:\\n\\n\n",
    "        **Domain-Specific Observations:**\\n\n",
    "        1. Memory: [Very brief observation here]\\n\n",
    "        2. Orientation: [Very brief observation here]\\n\n",
    "        3. Judgment and Problem Solving: [Very brief observation here]\\n\n",
    "        4. Community Affairs: [Very brief observation here]\\n\n",
    "        5. Home and Hobbies: [Very brief observation here]\\n\n",
    "        6. Personal Care: [Very brief observation here]\\n\\n\n",
    "        **CDR Score:**\\n[Insert barely CDR score here, e.g., 2.0]\"\"\"\n",
    "response = augmented_note(prompt, notes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG on multi notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_note_with_timing(prompt, note_text, id):\n",
    "    start_time = time.time()\n",
    "    if not isinstance(note_text, str):\n",
    "        note_text = str(note_text) \n",
    "    retrieved_docs = retrieve_documents(note_text)\n",
    "    additional_context = \" \".join(retrieved_docs)\n",
    "    combined_prompt = f\"{prompt} Here is some additional information: {additional_context}\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-model2\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": combined_prompt},\n",
    "                    {\"role\": \"user\", \"content\": note_text}\n",
    "                ],\n",
    "                temperature = 0,\n",
    "                max_tokens = 4096\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            return response.choices[0].message.content, duration, id\n",
    "        except:\n",
    "            print(\"Rate limit exceeded. Retrying in 60 seconds...\")\n",
    "            time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_groups(progress_notes_list, num_groups):\n",
    "    # Divide the list into 'num_groups' parts\n",
    "    avg_len = len(progress_notes_list) // num_groups\n",
    "    groups = [progress_notes_list[i * avg_len:(i + 1) * avg_len] for i in range(num_groups - 1)]\n",
    "    groups.append(progress_notes_list[(num_groups - 1) * avg_len:])  # Append the remaining items\n",
    "    return groups, avg_len\n",
    "\n",
    "progress_notes_list = note_df\n",
    "groups, size_of_each_group = divide_into_groups(notes, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_dementia_parallel_rag(note_text, max_workers=16):\n",
    "    prompt = \"\"\"Given the progress notes, assess what is the overall level of dementia based on the descriptions of the patient’s cognitive and functional abilities, provide the global CDR score (0, 0.5, 1, 2, or 3) and a brief justification. \n",
    "        Follow this format and do not include patient name in response.:\\n\\n\n",
    "        **Domain-Specific Observations:**\\n\n",
    "        1. Memory: [Very brief observation here]\\n\n",
    "        2. Orientation: [Very brief observation here]\\n\n",
    "        3. Judgment and Problem Solving: [Very brief observation here]\\n\n",
    "        4. Community Affairs: [Very brief observation here]\\n\n",
    "        5. Home and Hobbies: [Very brief observation here]\\n\n",
    "        6. Personal Care: [Very brief observation here]\\n\\n\n",
    "        **CDR Score:**\\n[Insert barely CDR score here, e.g., 2.0]\"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for index, note in enumerate(note_text):\n",
    "            futures.append(executor.submit(augmented_note_with_timing, prompt, note, index))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            response, duration, index = future.result()\n",
    "            cdr = extract_cdr_score(response)\n",
    "            results.append({\"case_id\": index, \"response\": response, \"CDR\": cdr, \"duration\": duration})\n",
    "    # Sort results by case_id to maintain the original order\n",
    "    results.sort(key=lambda x: x['case_id'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_group_index = 0\n",
    "path = \"../Results/RAG GPT\"\n",
    "\n",
    "for group_index, group in enumerate(groups[start_group_index:]):\n",
    "    print(f\"Processing group {group_index + start_group_index + 1} of {len(groups)}...\")\n",
    "    save_results = stage_dementia_parallel_rag(group, max_workers=16)\n",
    "\n",
    "    # Step 3: Save the results to a JSON file with the path\n",
    "    filename = f\"group_{group_index + start_group_index + 1}_results.json\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(save_results, json_file, indent=4)\n",
    "    print(f\"Results saved to {file_path}\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
